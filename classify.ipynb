{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d0e26b9-7f94-4165-821c-e1cd4ef3650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from jieba import cut\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "642fc3d8-6361-48b9-8605-8d41649f325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(filename):\n",
    "    \"\"\"读取文本并过滤无效字符和长度为1的词\"\"\"\n",
    "    words = []\n",
    "    with open(filename, 'r', encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            # 过滤无效字符\n",
    "            line = re.sub(r'[.【】0-9、——。，！~\\*]', '', line)\n",
    "            # 使用jieba.cut()方法对文本切词处理\n",
    "            line = cut(line)\n",
    "            # 过滤长度为1的词\n",
    "            line = filter(lambda word: len(word) > 1, line)\n",
    "            words.extend(line)\n",
    "    return words\n",
    "all_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a69910e8-0391-4796-88f9-16edae862081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(top_num):\n",
    "    \"\"\"遍历邮件建立词库后返回出现次数最多的词\"\"\"\n",
    "    filename_list = ['邮件_files/{}.txt'.format(i) for i in range(151)]\n",
    "    # 遍历邮件建立词库\n",
    "    for filename in filename_list:\n",
    "        all_words.append(get_words(filename))\n",
    "    # itertools.chain()把all_words内的所有列表组合成一个列表\n",
    "    # collections.Counter()统计词个数\n",
    "    freq = Counter(chain(*all_words))\n",
    "    return [i[0] for i in freq.most_common(top_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "caa6630c-3a36-41d1-bbb8-6ae33335b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = get_top_words(100)\n",
    "# 构建词-个数映射表\n",
    "vector = []\n",
    "for words in all_words:\n",
    "    '''\n",
    "    words:\n",
    "    ['国际', 'SCI', '期刊', '材料', '结构力学', '工程', '杂志', '国际', 'SCI', '期刊', '先进', '材料科学',\n",
    "    '材料', '工程', '杂志', '国际', 'SCI', '期刊', '图像处理', '模式识别', '人工智能', '工程', '杂志', '国际',\n",
    "    'SCI', '期刊', '数据', '信息', '科学杂志', '国际', 'SCI', '期刊', '机器', '学习', '神经网络', '人工智能',\n",
    "    '杂志', '国际', 'SCI', '期刊', '能源', '环境', '生态', '温度', '管理', '结合', '信息学', '杂志', '期刊',\n",
    "    '网址', '论文', '篇幅', '控制', '以上', '英文', '字数', '以上', '文章', '撰写', '语言', '英语', '论文',\n",
    "    '研究', '内容', '详实', '方法', '正确', '理论性', '实践性', '科学性', '前沿性', '投稿', '初稿', '需要',\n",
    "    '排版', '录用', '提供', '模版', '排版', '写作', '要求', '正规', '期刊', '正规', '操作', '大牛', '出版社',\n",
    "    '期刊', '期刊', '质量', '放心', '检索', '稳定', '邀请函', '推荐', '身边', '老师', '朋友', '打扰', '请谅解']\n",
    "    '''\n",
    "    word_map = list(map(lambda word: words.count(word), top_words))\n",
    "    '''\n",
    "    word_map:\n",
    "    [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "    10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
    "    0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    '''\n",
    "    vector.append(word_map)\n",
    "vector = np.array(vector)\n",
    "# 0-126.txt为垃圾邮件标记为1；127-151.txt为普通邮件标记为0\n",
    "labels = np.array([1]*127 + [0]*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b64d5e65-d4ec-4be1-99a0-a883a8a091e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(vector, labels)\n",
    "def predict(filename):\n",
    "    \"\"\"对未知邮件分类\"\"\"\n",
    "    # 构建未知邮件的词向量\n",
    "    words = get_words(filename)\n",
    "    current_vector = np.array(\n",
    "        tuple(map(lambda word: words.count(word), top_words)))\n",
    "    # 预测结果\n",
    "    result = model.predict(current_vector.reshape(1, -1))\n",
    "    return '垃圾邮件' if result == 1 else '普通邮件'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "935d66b7-18db-4fcf-9ee0-b359a99dba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.txt分类情况:垃圾邮件\n",
      "152.txt分类情况:垃圾邮件\n",
      "153.txt分类情况:垃圾邮件\n",
      "154.txt分类情况:垃圾邮件\n",
      "155.txt分类情况:普通邮件\n"
     ]
    }
   ],
   "source": [
    "print('151.txt分类情况:{}'.format(predict('邮件_files/151.txt')))\n",
    "print('152.txt分类情况:{}'.format(predict('邮件_files/152.txt')))\n",
    "print('153.txt分类情况:{}'.format(predict('邮件_files/153.txt')))\n",
    "print('154.txt分类情况:{}'.format(predict('邮件_files/154.txt')))\n",
    "print('155.txt分类情况:{}'.format(predict('邮件_files/155.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4dba8-e955-4190-a834-78f68695f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "    def __init__(self, method='high_frequency'):\n",
    "        \"\"\"\n",
    "        初始化特征选择器\n",
    "        :param method: 特征选择方法，可选'high_frequency'或'tf_idf'\n",
    "        \"\"\"\n",
    "        self.method = val\n",
    "        \n",
    "\n",
    "    def fit_transform(self, corpus, top_k=10):\n",
    "        \"\"\"\n",
    "        根据指定方法提取特征\n",
    "        :param corpus: 文本数据集\n",
    "        :param top_k: 高频词特征时选择的高频词数量\n",
    "        :return: 特征矩阵\n",
    "        \"\"\"\n",
    "        if self.method == 'high_frequency':\n",
    "            # 高频词特征\n",
    "            # 高频词特征\n",
    "            vectorizer = CountVectorizer()\n",
    "            X = vectorizer.fit_transform(corpus)\n",
    "            word_freq = X.sum(axis=0).A1  # 获取每个词的总词频\n",
    "            top_words_indices = word_freq.argsort()[::-1][:top_k]  # 获取词频最高的top_k个词的索引\n",
    "            top_words = [vectorizer.get_feature_names_out()[i] for i in top_words_indices]  # 获取对应的高频词\n",
    "            # 构造高频词特征矩阵\n",
    "            high_freq_vectorizer = CountVectorizer(vocabulary=top_words)\n",
    "            return high_freq_vectorizer.fit_transform(corpus)\n",
    "           \n",
    "        elif self.method == 'tf_idf':\n",
    "            # TF-IDF加权特征\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            return vectorizer.fit_transform(corpus)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid method. Please choose 'high_frequency' or 'tf_idf'.\")\n",
    "\n",
    "# 示例用法\n",
    "corpus = ['邮件_files/{}.txt'.format(i) for i in range(151)]\n",
    "\n",
    "val = input(\"Enter your method: \")\n",
    "selector = FeatureSelector(method=val)\n",
    "if selector.method == 'high_frequency':\n",
    "    high_freq_features = selector.fit_transform(corpus, top_k=10)\n",
    "    print(\"High Frequency Features:\")\n",
    "    print(high_freq_features.toarray())\n",
    "\n",
    "if selector.method == 'tf_idf':\n",
    "    tf_idf_features = selector.fit_transform(corpus)\n",
    "    print(\"\\nTF-IDF Features:\")\n",
    "    print(tf_idf_features.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
